{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d7ede9",
   "metadata": {},
   "source": [
    "The following cell performs sweeps of the lambda value. Within the `validation_train` loop, the following steps are executed for each value in the `alpha_grid`:\n",
    "\n",
    "- The function `lasso_regression` is called to fit a lasso regression model using the subject's transformed SC and FC matrices and the current `alpha` value.\n",
    "- The resulting transformation rules are saved to disk in a directory specific to the current window size and subject.\n",
    "- GPU memory is cleared and Python garbage collection is triggered to manage resources efficiently.\n",
    "\n",
    "This process is repeated for each regularization parameter in the grid, enabling systematic exploration of model performance across different penalty strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SC Density Sweeps - Helper Functions ##\n",
    "import cupy as cp\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "\n",
    "def calc_fc(ts_data, time_steps, starting_time):\n",
    "    \"\"\"\n",
    "    Calculate the functional connectivity matrix from time series data.\n",
    "    \"\"\"\n",
    "    n = ts_data.shape[1]\n",
    "    fc_matrix = cp.zeros((n, n))\n",
    "    fc_matrix = cp.corrcoef(ts_data[starting_time:time_steps + starting_time, :], rowvar=False)\n",
    "    return fc_matrix.astype(cp.float32)\n",
    "\n",
    "def load_connectomes(subject_id, time_steps=-1, starting_time=0):\n",
    "    \"\"\"\n",
    "    Load the data for a given subject and window ratio.\n",
    "    \"\"\"\n",
    "    # Data paths\n",
    "    function_ts_path = f\"ts_data/iPA_183/ts/ts_sub-{subject_id}_183.txt\"\n",
    "    sc_path = f\"ts_data/iPA_183/sc/sub-{subject_id}_SC.csv\"\n",
    "\n",
    "    # Get sc & fc matrices and return them\n",
    "    ts_data = cp.loadtxt(function_ts_path)\n",
    "    fc = calc_fc(ts_data, time_steps, starting_time)\n",
    "    sc = cp.loadtxt(sc_path)\n",
    "    cp.fill_diagonal(sc, cp.mean(sc))\n",
    "    return sc.astype(cp.float32), fc\n",
    "\n",
    "\n",
    "## SC Density Sweeps - Train ##\n",
    "import gc\n",
    "from lin_gen_model import calc_alpha_grid, lasso_regression, Subject\n",
    "from transformations import symmetric_modification\n",
    "import inout\n",
    "\n",
    "\n",
    "def validation_train(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID at different window sizes and penalty values.\n",
    "    \"\"\"\n",
    "    time_steps = 587 \n",
    "    sc, fc = load_connectomes(subject_id, time_steps=time_steps)\n",
    "    subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "    alpha_grid = calc_alpha_grid(subject.transformed_sc, subject.transformed_fc, 20)\n",
    "\n",
    "    print(f\"Window = {time_steps}, alpha_grid = {alpha_grid}\")\n",
    "\n",
    "    for num, alpha in enumerate(alpha_grid):\n",
    "        rules = lasso_regression(subject.transformed_sc, subject.transformed_fc, alpha, max_iter=100)\n",
    "        outdir = f\"sc_density_sweeps/{time_steps}/\"\n",
    "        inout.check_paths(outdir)\n",
    "        cp.savetxt(f\"{outdir}rules_sub-{subject_id}_lambda-{num}\", rules)\n",
    "\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        # Force Python garbage collection:\n",
    "        gc.collect()\n",
    "\n",
    "SUBJECT_IDs = ['032301', '032304', '032307']\n",
    "for subject_id in SUBJECT_IDs:\n",
    "    validation_train(subject_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1eee5",
   "metadata": {},
   "source": [
    "This cell implements the training workflow for subject-level models across multiple subjects using structural connectivity (SC) density sweeps. For each subject ID in the `SUBJECT_IDs` list, it loads the subject's SC and functional connectivity (FC) matrices, applies a symmetric transformation, and computes a grid of regularization parameters (`alpha_grid`). For each value in this grid, it fits a lasso regression model to learn transformation rules, saves the resulting rules to disk, and manages GPU memory and garbage collection to optimize resource usage. This process enables systematic exploration of model performance across different regularization strengths and window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ef9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SC Density Sweeps - Plot ##\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from transformations import inverse_symmetric_modification\n",
    "\n",
    "def make_validation_plots(subject_id):\n",
    "    fig1, axs_both_windows = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axs_both_windows = axs_both_windows.flatten()\n",
    "\n",
    "    fig2, axs_same_window = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axs_same_window = axs_same_window.flatten()\n",
    "\n",
    "    fig3, axs_diff_window = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axs_diff_window = axs_diff_window.flatten()\n",
    "\n",
    "    for plot_indx, window_size in enumerate((16, 65, 98, 130, 196, 326, 587)):\n",
    "        # Data paths\n",
    "        function_ts_path = f\"ts_data/iPA_183/ts/ts_sub-{subject_id}_183.txt\"\n",
    "        ts_data = cp.loadtxt(function_ts_path)\n",
    "\n",
    "        fc_same_window = calc_fc(ts_data, window_size, 0)\n",
    "        fc_diff_window = calc_fc(ts_data, window_size, 652-window_size)\n",
    "\n",
    "        sc_path = f\"ts_data/iPA_183/sc/sub-{subject_id}_SC.csv\"\n",
    "        sc = cp.loadtxt(sc_path)\n",
    "        cp.fill_diagonal(sc, 0)\n",
    "\n",
    "        r2s_same_window = []\n",
    "        r2s_diff_window = []\n",
    "        sc_densities = []\n",
    "        for indx in range(20):\n",
    "            rules_path = f\"sc_density_sweeps/{window_size}/rules_sub-{subject_id}_lambda-{indx}\"\n",
    "            rules = cp.loadtxt(rules_path)\n",
    "            rules = inverse_symmetric_modification(rules, 183)\n",
    "\n",
    "            predfc = sc @ rules @ sc\n",
    "\n",
    "            r2_same_window = r2_score(fc_same_window.get().flatten(), predfc.get().flatten())\n",
    "            r2s_same_window.append(r2_same_window)\n",
    "\n",
    "            r2_diff_window = r2_score(fc_diff_window.get().flatten(), predfc.get().flatten())\n",
    "            r2s_diff_window.append(r2_diff_window)\n",
    "\n",
    "            density = cp.count_nonzero(rules) / (rules.shape[0] ** 2)\n",
    "            sc_densities.append(density.get())\n",
    "\n",
    "        axs_both_windows[plot_indx].scatter(sc_densities, r2s_same_window, color=\"blue\")\n",
    "        axs_both_windows[plot_indx].scatter(sc_densities, r2s_diff_window, color=\"red\")\n",
    "        axs_both_windows[plot_indx].set_title(f\"R2 - Window Size: {window_size}/ 652\")\n",
    "        axs_both_windows[plot_indx].set_xlabel(\"Rules Density\")\n",
    "\n",
    "        axs_same_window[plot_indx].scatter(sc_densities, r2s_same_window, color=\"blue\")\n",
    "        axs_same_window[plot_indx].set_title(f\"R2 - Window Size: {window_size}/ 652\")\n",
    "        axs_same_window[plot_indx].set_xlabel(\"Rules Density\")\n",
    "\n",
    "        axs_diff_window[plot_indx].scatter(sc_densities, r2s_diff_window, color=\"red\")\n",
    "        axs_diff_window[plot_indx].set_title(f\"R2 - Window Size: {window_size}/ 652\")\n",
    "        axs_diff_window[plot_indx].set_xlabel(\"Rules Density\")\n",
    "\n",
    "    fig1.savefig(f\"r2_density_both_windows_sub-{subject_id}.png\")\n",
    "    fig2.savefig(f\"r2_density_same_window_sub-{subject_id}.png\")\n",
    "    fig3.savefig(f\"r2_density_diff_window_sub-{subject_id}.png\")\n",
    "\n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n",
    "    plt.close(fig3)\n",
    "\n",
    "SUBJECT_IDs = ['032304', '032302', '032307']\n",
    "for subject_id in SUBJECT_IDs:\n",
    "    make_validation_plots(subject_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c89e1d",
   "metadata": {},
   "source": [
    "This cell implements subject-level training using the Schaefer 100 parcellation. For each subject ID from 1 to 50, it loads the subject's structural connectivity (SC) and functional connectivity (FC) matrices, applies a symmetric transformation, and fits a model using a binary search to optimize the regularization parameter. The resulting transformation rules are saved for each subject. GPU memory is managed and garbage collection is performed after each subject to ensure efficient resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Train ##\n",
    "import gc\n",
    "import cupy as cp\n",
    "import inout\n",
    "from inout import get_schaefer100_sc, get_schaefer100_fc\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "\n",
    "def train_subject(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    sc, fc = get_schaefer100_sc(subject_id), get_schaefer100_fc(subject_id)\n",
    "    subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "    rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc, max_iter=10)\n",
    "\n",
    "    # Save the model\n",
    "    sl_dir = \"subject_level_log10\"\n",
    "    inout.check_paths(sl_dir)\n",
    "    cp.savetxt(f\"{sl_dir}/rules_sub-{subject_id}\", rules)\n",
    "\n",
    "    print(f\"Subject {subject_id} finished training with alpha: {alpha}\")\n",
    "    print()\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    train_subject(subject_id)\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06462938",
   "metadata": {},
   "source": [
    "This cell implements subject-level training using the Schaefer 100 parcellation, but applies a log base 10 transformation to the structural connectivity (SC) matrices before model fitting. For each subject ID from 1 to 50, it loads the subject's SC and functional connectivity (FC) matrices, transforms the SC matrix with `log10(sc + 1)`, applies a symmetric transformation, and fits a model using a binary search to optimize the regularization parameter. The resulting transformation rules are saved for each subject. GPU memory is managed and garbage collection is performed after each subject to ensure efficient resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52236dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Train (log base 10) ##\n",
    "import gc\n",
    "import cupy as cp\n",
    "import inout\n",
    "from inout import get_schaefer100_sc, get_schaefer100_fc\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "\n",
    "def train_subject(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    sc, fc = get_schaefer100_sc(subject_id), get_schaefer100_fc(subject_id)\n",
    "    sc = cp.log10(sc + 1)\n",
    "    subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "    rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc, max_iter=10)\n",
    "\n",
    "    # Save the model\n",
    "    sl_dir = \"subject_level_log10\"\n",
    "    inout.check_paths(sl_dir)\n",
    "    cp.savetxt(f\"{sl_dir}/rules_sub-{subject_id}\", rules)\n",
    "\n",
    "    print(f\"Subject {subject_id} finished training with alpha: {alpha}\")\n",
    "    print()\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    train_subject(subject_id)\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea0c31",
   "metadata": {},
   "source": [
    "This cell implements subject-level training where each subject's functional connectivity (FC) matrix is paired with the structural connectivity (SC) matrix from a different subject. For each subject ID, the FC is loaded for that subject, while the SC is loaded from another subject according to a deterministic mapping. The model is trained using these mismatched SC-FC pairs, and the resulting transformation rules are saved. GPU memory is managed and garbage collection is performed after each subject to ensure efficient resource usage. This approach allows for the assessment of how well models generalize when trained on SC from other individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6814d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Train w/ Other Subject's SC ##\n",
    "import gc\n",
    "import cupy as cp\n",
    "import inout\n",
    "from inout import get_schaefer100_sc, get_schaefer100_fc\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "\n",
    "def train_subject(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID.\n",
    "    \"\"\"\n",
    "    fc = get_schaefer100_fc(subject_id)\n",
    "\n",
    "    # Map each subject_id to another in a one-to-one function\n",
    "    if subject_id <= 40:\n",
    "        subject_id_sc = subject_id + 10\n",
    "    else:\n",
    "        subject_id_sc = (subject_id - 1) % 40 + 1\n",
    "    \n",
    "    # Load the data\n",
    "    sc = get_schaefer100_sc(subject_id_sc)\n",
    "    subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "    rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc, max_iter=10)\n",
    "\n",
    "    # Save the model\n",
    "    sl_dir = \"subject_level_other_sc\"\n",
    "    inout.check_paths(sl_dir)\n",
    "    cp.savetxt(f\"{sl_dir}/rules_sc-{subject_id_sc}_fc-{subject_id}\", rules)\n",
    "\n",
    "    print(f\"Subject {subject_id} FC w/ Subject {subject_id_sc} SC finished training with alpha: {alpha}\")\n",
    "    print()\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    train_subject(subject_id)\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d652d1",
   "metadata": {},
   "source": [
    "This cell implements subject-level training using null structural connectivity (SC) matrices. For each subject ID from 1 to 50, it loads the subject's functional connectivity (FC) matrix and iterates over 100 null SC matrices generated for that subject. Each null SC matrix is processed (with the medial wall removed), and a model is trained using the FC and the transformed null SC. The resulting transformation rules are saved for each null, allowing for statistical comparison against models trained with real SC. GPU memory is managed and garbage collection is performed after each null model to ensure efficient resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ebd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Train w/ SC nulls ##\n",
    "import gc\n",
    "import cupy as cp\n",
    "import inout\n",
    "from inout import get_schaefer100_fc\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "def train_subject(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID.\n",
    "    \"\"\"\n",
    "    fc = get_schaefer100_fc(subject_id)\n",
    "\n",
    "    for null_num in range(0, 100):\n",
    "    \n",
    "        # Load the data\n",
    "        sc = cp.loadtxt(f\"sc_nulls/{subject_id}/null_X{null_num}\")\n",
    "        sc = inout.remove_medial_wall(sc)\n",
    "        subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "        rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc, max_iter=10)\n",
    "\n",
    "        # Save the model\n",
    "        sl_dir = f\"rule_nulls/{subject_id}\"\n",
    "        inout.check_paths(sl_dir)\n",
    "        cp.savetxt(f\"{sl_dir}/null_rules{null_num}\", rules)\n",
    "\n",
    "        print(f\"Subject {subject_id}, null_num {null_num} finished training with alpha: {alpha}\")\n",
    "        print()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    train_subject(subject_id)\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28719f3a",
   "metadata": {},
   "source": [
    "This cell identifies statistically significant  rules at the subject level by comparing each subject's learned rules to a null distribution generated from 100 null models. For each subject, it loads the learned rules and the corresponding null distributions, computes p-values for each rule using a t-test, and sets non-significant rules (p > 0.05) to NaN. The resulting p-values and significant rules matrices are saved for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Find Significant Rules ##\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def compute_pvals(distribution, matrix):\n",
    "    n = matrix.shape[0]\n",
    "    df = n - 1\n",
    "\n",
    "    mean = distribution.mean(axis=1)\n",
    "    std = distribution.std(axis=1, ddof=1)\n",
    "    t_stat = (mean - matrix) / ((std + 1e-64) / np.sqrt(n))\n",
    "    p_values = 2 * t.sf(np.abs(t_stat), df)\n",
    "    return p_values\n",
    "\n",
    "def compute_sig_rules(p_values, matrix):\n",
    "    matrix[p_values > 0.05] = np.nan\n",
    "    return matrix\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    rules = np.loadtxt(f\"subject_level/rules_sub-{subject_id}\")\n",
    "\n",
    "    distribution = []\n",
    "    for null_num in range(100):\n",
    "        if not os.path.exists(f\"rule_nulls/{subject_id}/null_rules{null_num}\"):\n",
    "            continue\n",
    "        null_rules = np.loadtxt(f\"rule_nulls/{subject_id}/null_rules{null_num}\")\n",
    "        distribution.append(null_rules)\n",
    "    distribution = np.vstack(distribution).T\n",
    "\n",
    "    pvals = compute_pvals(distribution, rules)\n",
    "    sig_rules = compute_sig_rules(pvals, rules)\n",
    "\n",
    "    np.savetxt(f\"p_values_sub-{subject_id}\", pvals)\n",
    "    np.savetxt(f\"sig_rules_sub-{subject_id}\", sig_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03478828",
   "metadata": {},
   "source": [
    "This cell implements subject-level training using search information matrices derived from structural connectivity (SC). For each subject ID from 1 to 50, it loads the subject's functional connectivity (FC) matrix and the corresponding search information matrix (used as SC). The model is trained using these matrices and a symmetric transformation, and the resulting transformation rules are saved for each subject. GPU memory is managed and garbage collection is performed after each subject to ensure efficient resource usage. This approach allows for the assessment of how well search information can predict functional connectivity at the subject level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subject-Level - Train w/ Search Information ##\n",
    "import gc\n",
    "import cupy as cp\n",
    "import inout\n",
    "from inout import get_schaefer100_fc\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "\n",
    "def train_subject(subject_id):\n",
    "    \"\"\"\n",
    "    Train the subject-level model for a given subject ID.\n",
    "    \"\"\"\n",
    "    fc = get_schaefer100_fc(subject_id)\n",
    "\n",
    "    # Load the data\n",
    "    sc = cp.loadtxt(f\"search_information_from_sc/search_information_{subject_id}.txt\")\n",
    "    subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "    rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc, max_iter=10)\n",
    "\n",
    "    # Save the model\n",
    "    sl_dir = \"subject_level_search_information/\"\n",
    "    inout.check_paths(sl_dir)\n",
    "    cp.savetxt(f\"{sl_dir}/rules_sub-{subject_id}\", rules)\n",
    "\n",
    "    print(f\"Subject {subject_id} finished training with alpha: {alpha}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "for subject_id in range(1, 51):\n",
    "    train_subject(subject_id)\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ea598",
   "metadata": {},
   "source": [
    "This cell implements group-level training using the Schaefer 100 parcellation. For each subject ID from 1 to 50, it loads the subject's structural connectivity (SC) and functional connectivity (FC) matrices, applies a log base 10 transformation to the SC matrix, and then applies a symmetric transformation. The transformed SC and FC matrices are collected across subjects and stacked to form group-level datasets. The code prepares these datasets for further group-level model fitting, such as regression or matrix inversion, but the actual model fitting and saving steps are commented out. GPU memory is managed and garbage collection is performed after processing each subject to ensure efficient resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group-Level - Train ##\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import gc\n",
    "import inout\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lin_gen_model import Subject\n",
    "from transformations import symmetric_modification\n",
    "from inout import get_schaefer100_sc, get_schaefer100_fc\n",
    "\n",
    "def train_group(subject_ids):\n",
    "    \n",
    "    transformed_scs = []\n",
    "    transformed_fcs = []\n",
    "\n",
    "    for subject_id in subject_ids:\n",
    "        sc, fc = get_schaefer100_sc(subject_id), get_schaefer100_fc(subject_id)\n",
    "        sc = cp.log10(sc + 1)\n",
    "        subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "\n",
    "        transformed_scs.append(subject.transformed_sc.copy())\n",
    "        transformed_fcs.append(subject.transformed_fc.copy())\n",
    "\n",
    "        del sc, fc, subject\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        # Force Python garbage collection:\n",
    "        gc.collect()\n",
    "\n",
    "    X = cp.vstack(transformed_scs).T\n",
    "    y = cp.hstack(transformed_fcs)\n",
    "\n",
    "    del transformed_scs, transformed_fcs\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    # Force Python garbage collection:\n",
    "    gc.collect()\n",
    "\n",
    "    a = cp.linalg.pinv(transformed_scs[:6555, :6555*30])\n",
    "\n",
    "    #rules = LinearRegression(fit_intercept=False).fit(transformed_scs.T.astype(np.float32), transformed_fcs.astype(np.float32))\n",
    "\n",
    "    # Save the model\n",
    "    #sl_dir = \"group_level_log10\"\n",
    "    #inout.check_paths(sl_dir)\n",
    "    #np.savetxt(f\"{sl_dir}/rules\", rules)\n",
    "\n",
    "subject_ids = [subject_id for subject_id in range(1, 51)]\n",
    "train_group(subject_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812eea6",
   "metadata": {},
   "source": [
    "This cell implements subject-level model training for both schizophrenia (schz) and control (cntrl) groups using connectome data stored in an HDF5 file. For each subject in both groups, it loads the subject's structural connectivity (SC) and functional connectivity (FC) matrices, applies a symmetric transformation, and fits a model using a binary search to optimize the regularization parameter. The resulting transformation rules are saved for each subject in group-specific directories. This workflow enables comparison of learned connectivity transformations between schizophrenia and control subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Schizophrenia Subject-Level - Train ##\n",
    "import h5py\n",
    "import cupy as cp\n",
    "from lin_gen_model import Subject, binary_search_train\n",
    "from transformations import symmetric_modification\n",
    "import inout\n",
    "\n",
    "\n",
    "sc_ctrl_path = \"SC_FC_Connectomes/SC_number_of_fibers/ctrl\"\n",
    "sc_schz_path = \"SC_FC_Connectomes/SC_number_of_fibers/schz\"\n",
    "fc_ctrl_path = \"SC_FC_Connectomes/FC_correlation/ctrl\"\n",
    "fc_schz_path = \"SC_FC_Connectomes/FC_correlation/schz\"\n",
    "sc_dens_ctrl_path = \"SC_FC_Connectomes/SC_density/ctrl\"\n",
    "sc_dens_schz_path = \"SC_FC_Connectomes/SC_density/schz\"\n",
    "\n",
    "def get_mat(path, subject_id):\n",
    "    # Open the HDF5 file\n",
    "    with h5py.File(\"27_SCHZ_CTRL_dataset.mat\", \"r\") as f:\n",
    "        # Access the object reference datasets\n",
    "        refs = f[path]\n",
    "\n",
    "        # Dereference the objects\n",
    "        data = [cp.array(f[ref]) for ref in refs[:,0]][1][subject_id - 1]\n",
    "    return data\n",
    "\n",
    "for group in [\"schz\", \"cntrl\"]:\n",
    "    for subject_id in range(1,28):\n",
    "        # Load the data for the subject\n",
    "            if group == \"schz\":            \n",
    "                sc = get_mat(sc_schz_path, subject_id)\n",
    "                fc = get_mat(fc_schz_path, subject_id)\n",
    "            elif group == \"cntrl\":\n",
    "                sc = get_mat(sc_ctrl_path, subject_id)\n",
    "                fc = get_mat(fc_ctrl_path, subject_id)\n",
    "            cp.fill_diagonal(fc, 1)\n",
    "\n",
    "            # Create the subject object.\n",
    "            subject = Subject(subject_id, sc, fc, symmetric_modification)\n",
    "\n",
    "            # Make sure the output directory exists. If not created it.\n",
    "            outdir = f\"schz_results/{group}/\"\n",
    "            inout.check_paths(outdir)\n",
    "\n",
    "            # Train\n",
    "            rules, alpha = binary_search_train(subject.transformed_sc, subject.transformed_fc)\n",
    "            \n",
    "            print(f\"Subject {subject_id} finished training with alpha: {alpha}\")\n",
    "            print()\n",
    "\n",
    "            cp.savetxt(outdir + f\"rules_sub-{subject_id}\", rules)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
